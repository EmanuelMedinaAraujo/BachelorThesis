analytical:
  num_hidden_layer: 4
  hidden_layer_sizes: [ 64, 512, 256, 64 ]

  learning_rate: 1e-5
  batch_size: 32

  problems_per_epoch: 1000
  epochs: 10
  testing_interval: 1000 # Number of epochs after which to test the model
  optimizer: "Adam"

stb3:
  use_recurrent_policy: false

  non_recurrent_policy: "MlpPolicy"

  recurrent_policy: "MlpLstmPolicy"
  n_envs: 1
  n_steps: 128
  total_timesteps: 30000

  learning_rate: 1e-5
  batch_size: 32 # When using stable baselines, the batch size should be a factor of `n_steps * n_envs`
  epochs: 5

  gamma: 0.
  ent_coef: 0.0 # default value: 0.0
  log_std_init: 0.0 # default value: 0.0

  gae_lambda: 0.95
  clip_range: 0.2
  clip_range_vf: None
  norm_advantages: true
  vf_coef: 0.5
  max_grad_norm: 0.5
  use_sde: false



  testing_interval: 10000 # Number of steps after which to test the model

