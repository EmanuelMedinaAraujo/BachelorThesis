analytical:
  num_hidden_layer: 6
  hidden_layer_sizes: [ 64, 512, 1024, 512, 256, 64 ]

  learning_rate: 1e-5
  batch_size: 64

  problems_per_epoch: 1024
  epochs: 5000
  testing_interval: 1000 # Number of epochs after which to test the model
  optimizer: "Adam"

  output_type: "BetaDist" # "Normal", "NormDist", "ReparameterizationDist", "RandomSampleDist", "BetaDist"

stb3:
  use_recurrent_policy: false

  non_recurrent_policy: "MlpPolicy"

  recurrent_policy: "MlpLstmPolicy"
  n_envs: 6
  n_steps: 4
  total_timesteps: 1000000

  learning_rate: 0.01 # default value: 0.0003
  batch_size: 512 # When using stable baselines, the batch size should be a factor of `n_steps * n_envs`
  epochs: 171

  gamma: 0.0
  ent_coef: 0.3923435836538981 # default value: 0.0, PPO 0.01
  log_std_init: 3.146588794820072 # default value: 0.0

  ##################
  gae_lambda: 0.95      # default value: 0.95
  clip_range: 0.2       # default value: 0.2
  norm_advantages: true # default value: true
  vf_coef: 0.5          # default value: 0.5
  max_grad_norm: 0.5    # default value: 0.5
  net_arch_type: "tiny"      # from "tiny", "small", "medium"
  ortho_init: true      # default value: true
  activation_fn_name: "tanh" # from "tanh", "relu", "elu", "leaky_relu". Only used for hyperparameter optimization
  lr_schedule: "constant" # from "linear", "constant" # Not implemented yet
  # For recurrent_policy
  enable_critic_lstm: true # default value: true
  lstm_hidden_size: 256     # default value: 256
  ####################

  testing_interval: 100000 # Number of steps after which to test the model